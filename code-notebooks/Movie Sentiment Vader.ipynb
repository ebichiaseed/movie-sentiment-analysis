{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1EO3XD0wYLVVDZHo8YOmxJBMJElcY4WwT","timestamp":1743876157425}],"machine_shape":"hm","gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Exploring VADER as a sentiment analysis tool\n","\n","In this notebook, we began by cleaning the movie review dataset (removing HTML tags and extra white spaces) to reduce noise. We deliberately retained capitalisation, punctuation, emojis, and slang, as these elements contribute meaningfully to VADER's sentiment calculations.\n","\n","We then applied the VADER sentiment analyzer to each review to extract positive, negative, neutral, and compound scores.\n","\n","Using the compound score, we classified reviews as either positive or negative and computed the overall prediction accuracy.\n","\n","To further refine our approach, we identified words missing from the VADER lexicon and experimented with different compound score thresholds. We found that a threshold of 0.5 yielded the best accuracy at 0.712.\n","\n","Overall, our exploration suggests that while VADER is effective for shorter, informal social media texts, it may not be the optimal tool for analyzing the more complex sentiment expressed in movie reviews."],"metadata":{"id":"6IfqN_jjq8LG"}},{"cell_type":"code","source":["import torch\n","from torch import cuda\n","\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3fhqhCFjAfa","executionInfo":{"status":"ok","timestamp":1743736523849,"user_tz":-480,"elapsed":7799,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"7696bd64-4fcd-4305-ebb4-af1be5e9fb19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["import nltk\n","import re\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","from google.colab import drive\n","!pip install vaderSentiment\n","nltk.download('punkt_tab')\n","nltk.download('punkt')"],"metadata":{"id":"fX4kKj-dQW2H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743736890905,"user_tz":-480,"elapsed":3592,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"4ac00652-d1b9-4cc3-e5d7-87e4d693582b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.11/dist-packages (3.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n"]}]},{"cell_type":"markdown","source":["# Preparing Dataset"],"metadata":{"id":"OAc7hQpAQRfE"}},{"cell_type":"code","source":["drive.mount('/content/drive')\n","\n","nltk.download('punkt')\n","\n","neg_df = pd.read_csv('/content/drive/MyDrive/it1244/negcsv.csv')\n","pos_df = pd.read_csv('/content/drive/MyDrive/it1244/poscsv.csv')\n","\n","\n","neg_df['label'] = 0\n","pos_df['label'] = 1\n","\n","df = pd.concat([neg_df, pos_df], ignore_index=True)\n","\n","print(\"Sample rows:\")\n","print(df.head())\n","print(\"\\nTotal reviews:\", len(df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kubkxVccl0Ui","executionInfo":{"status":"ok","timestamp":1743736637659,"user_tz":-480,"elapsed":92387,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"d9383555-9381-4cbf-9f2d-de81d592a982"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Sample rows:\n","    FileName                                            Content  label\n","0  23129.txt  Not even Goebbels could have pulled off a prop...      0\n","1  22912.txt  A plot that fizzled and reeked of irreconcilab...      0\n","2  23622.txt  The first look on the cover of this picture, i...      0\n","3  23637.txt  A drama at its very core, \"Anna\" displays that...      0\n","4  23109.txt  When THE MAGIC OF LASSIE opened at Radio City ...      0\n","\n","Total reviews: 50000\n"]}]},{"cell_type":"markdown","source":["# Cleaning Dataset"],"metadata":{"id":"Rk548nC7ymUh"}},{"cell_type":"code","source":["# The clean_text function removes only HTML tags and extra white spaces from the reviews.\n","# We intentionally keep punctuations and capitalisations intact because VADER leverages these features for sentiment scoring.\n","\n","def clean_text(text):\n","    text = BeautifulSoup(text, \"html.parser\").get_text()\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","df['Content'] = df['Content'].apply(clean_text)\n","\n","print(\"Cleaned sample rows:\")\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coMWecA8y1iT","executionInfo":{"status":"ok","timestamp":1743736921745,"user_tz":-480,"elapsed":30595,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"1bb8737f-4f43-4d99-c841-fcce7dc7b47e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned sample rows:\n","    FileName                                            Content  label\n","0  23129.txt  Not even Goebbels could have pulled off a prop...      0\n","1  22912.txt  A plot that fizzled and reeked of irreconcilab...      0\n","2  23622.txt  The first look on the cover of this picture, i...      0\n","3  23637.txt  A drama at its very core, \"Anna\" displays that...      0\n","4  23109.txt  When THE MAGIC OF LASSIE opened at Radio City ...      0\n"]}]},{"cell_type":"code","source":["nltk.download('vader_lexicon')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eD55TXuymaiL","executionInfo":{"status":"ok","timestamp":1743736938007,"user_tz":-480,"elapsed":45,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"57a33ca8-5db9-42be-dad7-97f9a5ae21d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# Getting sentiment scores of first few rows"],"metadata":{"id":"VadRHbDGQgqd"}},{"cell_type":"code","source":["analyzer = SentimentIntensityAnalyzer()\n","\n","# This function computes VADER sentiment scores for a given text.\n","# The analyzer.polarity_scores function returns a dictionary containing negative, neutral, positive, and compound sentiment scores.\n","def get_vader_scores(text):\n","    return analyzer.polarity_scores(text)\n","\n","\n","df[['neg', 'neu', 'pos', 'compound']] = df['Content'].apply(\n","    lambda x: pd.Series(get_vader_scores(x))\n",")\n","print(\"\\nSentiment scores (first few rows):\")\n","print(df[['Content', 'neg', 'neu', 'pos', 'compound']].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcIvUqlul7ch","executionInfo":{"status":"ok","timestamp":1743737056695,"user_tz":-480,"elapsed":117506,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"f6e8ac05-8de7-4db9-dc2d-84de063c8b85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sentiment scores (first few rows):\n","                                             Content    neg    neu    pos  \\\n","0  Not even Goebbels could have pulled off a prop...  0.078  0.846  0.076   \n","1  A plot that fizzled and reeked of irreconcilab...  0.223  0.699  0.077   \n","2  The first look on the cover of this picture, i...  0.128  0.677  0.195   \n","3  A drama at its very core, \"Anna\" displays that...  0.108  0.754  0.138   \n","4  When THE MAGIC OF LASSIE opened at Radio City ...  0.059  0.840  0.102   \n","\n","   compound  \n","0   -0.5218  \n","1   -0.9704  \n","2    0.8690  \n","3    0.9866  \n","4    0.7453  \n"]}]},{"cell_type":"markdown","source":["# Classifying reviews based on default threshold\n"],"metadata":{"id":"twLkEnZWQrjE"}},{"cell_type":"code","source":["# Apply VADER sentiment analysis threshold to classify reviews.\n","# The default threshold is:\n","# - Positive review: compound score >= 0.05\n","# - Negative review: compound score < 0.05\n","\n","df['Predicted Sentiment'] = df['compound'].apply(\n","    lambda score: 1 if score >= 0.05 else 0\n",")\n","\n","print(\"\\nFirst few rows with predictions:\")\n","print(df[['Content', 'Predicted Sentiment', 'compound', 'label']].head())\n","\n","\n","correct_predictions = (df['Predicted Sentiment'] == df['label']).sum()\n","accuracy = correct_predictions / len(df)\n","print(f\"\\nAccuracy of VADER sentiment analysis (threshold=0.05): {accuracy:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JAEdTHIjl91s","executionInfo":{"status":"ok","timestamp":1743737056704,"user_tz":-480,"elapsed":12,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"8ddc3530-4b39-4447-a042-72ea49258551"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","First few rows with predictions:\n","                                             Content  Predicted Sentiment  \\\n","0  Not even Goebbels could have pulled off a prop...                    0   \n","1  A plot that fizzled and reeked of irreconcilab...                    0   \n","2  The first look on the cover of this picture, i...                    1   \n","3  A drama at its very core, \"Anna\" displays that...                    1   \n","4  When THE MAGIC OF LASSIE opened at Radio City ...                    1   \n","\n","   compound  label  \n","0   -0.5218      0  \n","1   -0.9704      0  \n","2    0.8690      0  \n","3    0.9866      0  \n","4    0.7453      0  \n","\n","Accuracy of VADER sentiment analysis (threshold=0.05): 0.70\n"]}]},{"cell_type":"markdown","source":["# Analysis of Results"],"metadata":{"id":"je-ZwXB1RZvB"}},{"cell_type":"code","source":["# This function finds unknown words in a text.\n","# It tokenizes the text and then identifies words that are not present in VADER's lexicon.\n","# Finding unknown words from reviews that are not in VADER's lexicon is important because it highlights a limitation of VADER. This could be one possible reason for the lower accuracy observed.\n","\n","def find_unknown_words(text):\n","    tokens = nltk.word_tokenize(text)\n","    unknown_words = [word for word in tokens if word.lower() not in analyzer.lexicon]\n","    return unknown_words\n","\n","df['unknown_words'] = df['Content'].apply(find_unknown_words)\n","\n","# Flatten the list of unknown words across all reviews\n","all_unknown_words = df['unknown_words'].sum()  # Combines lists into a single list\n","unique_unknown_words = list(set(all_unknown_words))  # Unique unknown words\n","\n","print(f\"\\nSome unknown words not in VADER's lexicon: {unique_unknown_words[:10]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fSMjH2l5mAxd","executionInfo":{"status":"ok","timestamp":1743742684551,"user_tz":-480,"elapsed":5627583,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"a6039c9c-5965-4940-a930-7cd656881c21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Some unknown words not in VADER's lexicon: ['Stallone\\x97that', 'Deathstalker', 'more.Robin', 'harkness', 'chiselled', 'ills', 'rs', 'Bluest', 'Pitts', 'list.Rating']\n"]}]},{"cell_type":"markdown","source":["Extracting wrongly classified examples and more performance metrics."],"metadata":{"id":"H-r88adgRV-x"}},{"cell_type":"code","source":["# Identify reviews where the predicted sentiment does not match the true label.\n","wrongly_labeled = df[df['Predicted Sentiment'] != df['label']]\n","\n","def extract_words(text):\n","    return nltk.word_tokenize(text)\n","\n","wrongly_labeled['Words'] = wrongly_labeled['Content'].apply(extract_words)\n","\n","wrongly_labeled_table = wrongly_labeled[['Content', 'Predicted Sentiment', 'label', 'Words']]\n","print(\"\\nSome wrongly labeled examples:\")\n","print(wrongly_labeled_table.head())\n","\n","\n","# Compute accuracy and other classification metrics (precision, recall, f1-score).\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n","\n","    acc = accuracy_score(labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n","    return {\n","        \"accuracy\": acc,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1\n","    }\n","\n","# Convert VADER compound scores to pseudo-logits (values that represent the model's confidence in each class before being converted into probabilities.)\n","# The compound score ranges from -1 (most negative) to 1 (most positive). We map it to probabilities: pos_prob = (compound + 1) / 2, neg_prob = 1 - pos_prob\n","logits = []\n","for c in df['compound']:\n","    pos_prob = (c + 1.0) / 2.0\n","    neg_prob = 1.0 - pos_prob\n","    logits.append([neg_prob, pos_prob])\n","\n","# Convert the logits and labels into torch tensors.\n","logits = torch.tensor(logits)\n","labels = torch.tensor(df['label'].values)\n","eval_pred = (logits, labels)\n","\n","metrics_result = compute_metrics(eval_pred)\n","print(\"\\nDetailed Metrics with default threshold interpretation:\")\n","for k, v in metrics_result.items():\n","    print(f\"{k.capitalize()}: {v:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I5eah615mjJv","executionInfo":{"status":"ok","timestamp":1743742705084,"user_tz":-480,"elapsed":20538,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"35febf85-d1e5-40ee-ca1e-c310d2e28287"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-2bf9f27671f6>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  wrongly_labeled['Words'] = wrongly_labeled['Content'].apply(extract_words)\n","<ipython-input-14-2bf9f27671f6>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  predictions = torch.argmax(torch.tensor(logits), dim=-1)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Some wrongly labeled examples:\n","                                             Content  Predicted Sentiment  \\\n","2  The first look on the cover of this picture, i...                    1   \n","3  A drama at its very core, \"Anna\" displays that...                    1   \n","4  When THE MAGIC OF LASSIE opened at Radio City ...                    1   \n","5  There are few uplifting things to say about th...                    1   \n","7  I find it rather useless to comment on this \"m...                    1   \n","\n","   label                                              Words  \n","2      0  [The, first, look, on, the, cover, of, this, p...  \n","3      0  [A, drama, at, its, very, core, ,, ``, Anna, '...  \n","4      0  [When, THE, MAGIC, OF, LASSIE, opened, at, Rad...  \n","5      0  [There, are, few, uplifting, things, to, say, ...  \n","7      0  [I, find, it, rather, useless, to, comment, on...  \n","\n","Detailed Metrics with default threshold interpretation:\n","Accuracy: 0.696\n","Precision: 0.649\n","Recall: 0.855\n","F1: 0.738\n"]}]},{"cell_type":"markdown","source":["# Exploring different thresholds"],"metadata":{"id":"nNYec3iISOae"}},{"cell_type":"code","source":["# Here, we define a list of thresholds to test. Adjusting the threshold can help improve the accuracy of the VADER model.\n","thresholds = [-0.1, 0.0, 0.05, 0.1, 0.2, 0.5]\n","results = []\n","\n","for t in thresholds:\n","    df['Predicted_T'] = df['compound'].apply(lambda x: 1 if x >= t else 0)\n","\n","    y_true = df['label']\n","    y_pred = df['Predicted_T']\n","    acc = accuracy_score(y_true, y_pred)\n","    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n","\n","    results.append({\n","        'Threshold': t,\n","        'Accuracy': acc,\n","        'Precision': prec,\n","        'Recall': rec,\n","        'F1': f1\n","    })\n","\n","print(\"\\nThreshold Tuning Results:\")\n","for r in results:\n","    print(f\"Threshold={r['Threshold']}: Accuracy={r['Accuracy']:.3f}, \"\n","          f\"Precision={r['Precision']:.3f}, Recall={r['Recall']:.3f}, F1={r['F1']:.3f}\")\n"],"metadata":{"id":"o1UXATI0lj9H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743742705167,"user_tz":-480,"elapsed":91,"user":{"displayName":"kate","userId":"18126128210209369393"}},"outputId":"addfb7a6-63f9-4aad-8f88-7f36b0d620fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Threshold Tuning Results:\n","Threshold=-0.1: Accuracy=0.694, Precision=0.645, Recall=0.860, F1=0.737\n","Threshold=0.0: Accuracy=0.696, Precision=0.649, Recall=0.856, F1=0.738\n","Threshold=0.05: Accuracy=0.697, Precision=0.650, Recall=0.853, F1=0.738\n","Threshold=0.1: Accuracy=0.699, Precision=0.652, Recall=0.851, F1=0.738\n","Threshold=0.2: Accuracy=0.702, Precision=0.657, Recall=0.844, F1=0.739\n","Threshold=0.5: Accuracy=0.712, Precision=0.676, Recall=0.812, F1=0.738\n"]}]},{"cell_type":"markdown","source":["# Conclusion\n","\n","In conclusion, our threshold tuning results indicate that a threshold of 0.5 yields the best performance, with the highest accuracy among the thresholds tested. However, even at this optimal threshold, the overall accuracy remains relatively low. This suggests that the VADER sentiment analysis model may not be sufficiently effective for movie sentiment analysis."],"metadata":{"id":"vAAUbxY8C5Di"}}]}